\section{関連研究}
推薦システムの透明性を高める説明可能性（Explainability）は近年重要な課題であり, 特徴ベース手法から LLM を用いた生成型手法まで多様なアプローチが体系化されている[1]. 
特に, 評価根拠を明示するため, ユーザやアイテムの潜在表現を解釈可能なアスペクトに写像する手法や, アテンションにより重要度を可視化する研究が進んでいる[2,3]. 
映画推薦でも, レビューやメタデータから嗜好要因を抽出する試みが行われているが[4], これらを user/movie 等の構造系列に分解し, 線形モデルの安定性を用いて要因寄与を一貫して定量化する枠組みは依然として独自性が高い.
